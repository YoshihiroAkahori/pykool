{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBRP Dry Protocol - バイオインフォマティクス解析自動化パイプライン\n",
    "\n",
    "このノートブックは、Eric Koolラボの論文「Reactivity-based RNA profiling for analyzing transcriptome interactions of small molecules in human cells」のドライプロトコル部分を自動化します。\n",
    "\n",
    "**対象ユーザー**: バイオインフォマティクス初学者  \n",
    "**入力**: FASTQファイル  \n",
    "**出力**: RNA-薬物相互作用解析結果\n",
    "\n",
    "## 使用方法\n",
    "1. 設定セクションで入力ファイルパスを指定\n",
    "2. 「Run All Cells」で全自動実行\n",
    "3. 結果は`data/results/`フォルダに保存されます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定と初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# プロジェクトルートディレクトリを設定\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# ログ設定\n",
    "log_file = PROJECT_ROOT / 'logs' / f'rbrp_pipeline_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"🧬 RBRP Dry Protocol Pipeline Started\")\n",
    "print(f\"📁 Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"📝 Log File: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 設定ファイル読み込み・入力ファイル指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ユーザー設定 =====\n",
    "# ここで入力ファイルを指定してください\n",
    "\n",
    "# 入力FASTQファイルのパス（複数サンプル対応）\n",
    "INPUT_FASTQ_FILES = {\n",
    "    'sample1_probe_only': '/path/to/sample1_probe_only.fastq',\n",
    "    'sample1_probe_drug': '/path/to/sample1_probe_drug.fastq',\n",
    "    'sample2_DMSO_ctrl': '/path/to/sample2_DMSO_ctrl.fastq',\n",
    "    'sample2_drug_ctrl': '/path/to/sample2_drug_ctrl.fastq'\n",
    "}\n",
    "\n",
    "# 参照ゲノムファイル\n",
    "REFERENCE_FILES = {\n",
    "    'genome_fasta': '/path/to/genome.fa',\n",
    "    'genome_gtf': '/path/to/genome.gtf',\n",
    "    'transcriptome_index': '/path/to/transcriptome_index',\n",
    "    'adapter_fasta': '/path/to/adapter.fa'\n",
    "}\n",
    "\n",
    "# バーコード情報\n",
    "BARCODES = {\n",
    "    'sample1_probe_only': 'GGTT',\n",
    "    'sample1_probe_drug': 'TTGT', \n",
    "    'sample2_DMSO_ctrl': 'ACCT',\n",
    "    'sample2_drug_ctrl': 'CAAT'\n",
    "}\n",
    "\n",
    "# 解析パラメータ\n",
    "ANALYSIS_PARAMS = {\n",
    "    'min_read_length': 25,\n",
    "    'min_rpkm': 1,\n",
    "    'min_sequencing_depth': 200,\n",
    "    'rbrp_score_threshold': 0.12,\n",
    "    'p_value_threshold': 0.05\n",
    "}\n",
    "\n",
    "print(\"✅ 設定完了\")\n",
    "print(f\"📊 解析対象サンプル数: {len(INPUT_FASTQ_FILES)}\")\n",
    "logger.info(f\"Analysis started with {len(INPUT_FASTQ_FILES)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 依存関係チェック・外部ツール確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_external_tools():\n",
    "    \"\"\"外部ツールの存在確認\"\"\"\n",
    "    required_tools = [\n",
    "        'fastqc',\n",
    "        'bowtie2',\n",
    "        'gffread',\n",
    "        'wiggletools',\n",
    "        'bedGraphToBigWig',\n",
    "        'wigToBigWig'\n",
    "    ]\n",
    "    \n",
    "    missing_tools = []\n",
    "    \n",
    "    for tool in required_tools:\n",
    "        try:\n",
    "            result = subprocess.run(['which', tool], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"✅ {tool}: {result.stdout.strip()}\")\n",
    "            else:\n",
    "                missing_tools.append(tool)\n",
    "                print(f\"❌ {tool}: 見つかりません\")\n",
    "        except Exception as e:\n",
    "            missing_tools.append(tool)\n",
    "            print(f\"❌ {tool}: エラー - {e}\")\n",
    "    \n",
    "    if missing_tools:\n",
    "        print(f\"\\n⚠️ 以下のツールが不足しています: {', '.join(missing_tools)}\")\n",
    "        print(\"インストール方法はREADME.mdを参照してください\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n🎉 すべての必要ツールが利用可能です\")\n",
    "        return True\n",
    "\n",
    "tools_available = check_external_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. パイプライン実行関数群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(cmd, description, check=True):\n",
    "    \"\"\"コマンド実行のヘルパー関数\"\"\"\n",
    "    logger.info(f\"実行中: {description}\")\n",
    "    logger.debug(f\"コマンド: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=check, \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            logger.info(f\"✅ 完了: {description}\")\n",
    "            return result\n",
    "        else:\n",
    "            logger.error(f\"❌ 失敗: {description}\")\n",
    "            logger.error(f\"エラー出力: {result.stderr}\")\n",
    "            if check:\n",
    "                raise subprocess.CalledProcessError(result.returncode, cmd)\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ 例外発生: {description} - {e}\")\n",
    "        if check:\n",
    "            raise\n",
    "        return None\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"出力ディレクトリ作成\"\"\"\n",
    "    dirs = [\n",
    "        'data/processed/fastqc',\n",
    "        'data/processed/trimmed', \n",
    "        'data/processed/aligned',\n",
    "        'data/processed/rbrp_scores',\n",
    "        'data/results/bigwig',\n",
    "        'data/results/figures'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        (PROJECT_ROOT / dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logger.info(\"📁 出力ディレクトリを作成しました\")\n",
    "\n",
    "create_output_dirs()\n",
    "print(\"📁 出力ディレクトリ準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ステップ1: 品質管理・デマルチプレックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_quality_control_and_demultiplex():\n",
    "    \"\"\"ステップ1: 品質管理とデマルチプレックス\"\"\"\n",
    "    print(\"\\n🔍 ステップ1: 品質管理・デマルチプレックス開始\")\n",
    "    \n",
    "    for sample_name, fastq_path in tqdm(INPUT_FASTQ_FILES.items(), desc=\"Processing samples\"):\n",
    "        if not Path(fastq_path).exists():\n",
    "            logger.warning(f\"⚠️ ファイルが見つかりません: {fastq_path}\")\n",
    "            continue\n",
    "            \n",
    "        # FastQC実行\n",
    "        fastqc_cmd = f\"fastqc -o {PROJECT_ROOT}/data/processed/fastqc {fastq_path}\"\n",
    "        run_command(fastqc_cmd, f\"FastQC for {sample_name}\")\n",
    "        \n",
    "        # デマルチプレックス（バーコードが指定されている場合）\n",
    "        if sample_name in BARCODES:\n",
    "            barcode = BARCODES[sample_name]\n",
    "            output_file = PROJECT_ROOT / f\"data/processed/{sample_name}_demux.fastq\"\n",
    "            \n",
    "            # 簡単なバーコード抽出（実際のsplitFastq.plの代替）\n",
    "            demux_cmd = f\"\"\"grep -A 3 \"^@.*{barcode}\" {fastq_path} | grep -v \"^--$\" > {output_file}\"\"\"\n",
    "            run_command(demux_cmd, f\"Demultiplexing {sample_name}\", check=False)\n",
    "            \n",
    "            logger.info(f\"✅ {sample_name}: デマルチプレックス完了\")\n",
    "    \n",
    "    print(\"✅ ステップ1完了: 品質管理・デマルチプレックス\")\n",
    "\n",
    "step1_quality_control_and_demultiplex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ステップ2: PCR重複除去・トリミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_remove_duplicates_and_trim():\n",
    "    \"\"\"ステップ2: PCR重複除去とトリミング\"\"\"\n",
    "    print(\"\\n✂️ ステップ2: PCR重複除去・トリミング開始\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing trimming\"):\n",
    "        input_file = PROJECT_ROOT / f\"data/processed/{sample_name}_demux.fastq\"\n",
    "        \n",
    "        if not input_file.exists():\n",
    "            logger.warning(f\"⚠️ 入力ファイルが見つかりません: {input_file}\")\n",
    "            continue\n",
    "        \n",
    "        # PCR重複除去（簡易版）\n",
    "        rmdup_file = PROJECT_ROOT / f\"data/processed/{sample_name}_rmdup.fastq\"\n",
    "        rmdup_cmd = f\"\"\"awk '/^@/ {{if (seen[$0]++) next}} 1' {input_file} > {rmdup_file}\"\"\"\n",
    "        run_command(rmdup_cmd, f\"Remove duplicates for {sample_name}\")\n",
    "        \n",
    "        # トリミング\n",
    "        trimmed_file = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed.fastq\"\n",
    "        \n",
    "        # アダプター配列除去とクオリティトリミング\n",
    "        trim_cmd = f\"\"\"cutadapt -a AGATCGGAAGAGCGGTTCAG -q 30 -m {ANALYSIS_PARAMS['min_read_length']} \\\n",
    "                     -o {trimmed_file} {rmdup_file}\"\"\"\n",
    "        \n",
    "        run_command(trim_cmd, f\"Trimming adapters for {sample_name}\", check=False)\n",
    "        logger.info(f\"✅ {sample_name}: トリミング完了\")\n",
    "    \n",
    "    print(\"✅ ステップ2完了: PCR重複除去・トリミング\")\n",
    "\n",
    "step2_remove_duplicates_and_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ステップ3: 配列アライメント・転写産物発現量計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_alignment_and_expression():\n",
    "    \"\"\"ステップ3: 配列アライメントと転写産物発現量計算\"\"\"\n",
    "    print(\"\\n🧬 ステップ3: アライメント・発現量計算開始\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing alignment\"):\n",
    "        trimmed_file = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed.fastq\"\n",
    "        \n",
    "        if not trimmed_file.exists():\n",
    "            logger.warning(f\"⚠️ トリミング済みファイルが見つかりません: {trimmed_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Bowtie2でアライメント\n",
    "        sam_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.sam\"\n",
    "        \n",
    "        align_cmd = f\"\"\"bowtie2 -U {trimmed_file} -S {sam_file} \\\n",
    "                       -x {REFERENCE_FILES['transcriptome_index']} \\\n",
    "                       --non-deterministic --time\"\"\"\n",
    "        \n",
    "        run_command(align_cmd, f\"Alignment for {sample_name}\")\n",
    "        \n",
    "        # RPKM計算\n",
    "        rpkm_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rpkm\"\n",
    "        rpkm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rpkm.py -i {sam_file} -o {rpkm_file}\"\"\"\n",
    "        \n",
    "        run_command(rpkm_cmd, f\"RPKM calculation for {sample_name}\", check=False)\n",
    "        \n",
    "        # RTstop計算\n",
    "        rt_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        rt_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rtstops.py \\\n",
    "                    -i {sam_file} -o {rt_file} -r {rpkm_file} -c {ANALYSIS_PARAMS['min_rpkm']}\"\"\"\n",
    "        \n",
    "        run_command(rt_cmd, f\"RTstop calculation for {sample_name}\", check=False)\n",
    "        logger.info(f\"✅ {sample_name}: アライメント・発現量計算完了\")\n",
    "    \n",
    "    print(\"✅ ステップ3完了: アライメント・発現量計算\")\n",
    "\n",
    "step3_alignment_and_expression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ステップ4: RBRPスコア計算・統計解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_rbrp_score_calculation():\n",
    "    \"\"\"ステップ4: RBRPスコア計算と統計解析\"\"\"\n",
    "    print(\"\\n📊 ステップ4: RBRPスコア計算・統計解析開始\")\n",
    "    \n",
    "    # サンプルをグループ分け\n",
    "    probe_samples = [k for k in INPUT_FASTQ_FILES.keys() if 'probe' in k]\n",
    "    control_samples = [k for k in INPUT_FASTQ_FILES.keys() if 'ctrl' in k or 'DMSO' in k]\n",
    "    \n",
    "    print(f\"📋 プローブサンプル: {probe_samples}\")\n",
    "    print(f\"📋 コントロールサンプル: {control_samples}\")\n",
    "    \n",
    "    # バックグラウンドRTstopファイルをマージ\n",
    "    if len(control_samples) >= 2:\n",
    "        control_files = [f\"{PROJECT_ROOT}/data/processed/aligned/{s}.rt\" for s in control_samples]\n",
    "        merged_control = PROJECT_ROOT / \"data/processed/rbrp_scores/merged_control.rt\"\n",
    "        \n",
    "        merge_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/merge_rt_files.py \\\n",
    "                       -i {':'.join(control_files)} -o {merged_control}\"\"\"\n",
    "        run_command(merge_cmd, \"Merging control RTstop files\", check=False)\n",
    "    \n",
    "    # 各プローブサンプルのRBRPスコア計算\n",
    "    for sample_name in tqdm(probe_samples, desc=\"Calculating RBRP scores\"):\n",
    "        rt_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        \n",
    "        if not rt_file.exists():\n",
    "            logger.warning(f\"⚠️ RTファイルが見つかりません: {rt_file}\")\n",
    "            continue\n",
    "        \n",
    "        # RTファイル正規化\n",
    "        normalized_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_normalized.rt\"\n",
    "        norm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/normalize_rt_file.py \\\n",
    "                      -i {rt_file} -o {normalized_file} -d 32 -l 32\"\"\"\n",
    "        run_command(norm_cmd, f\"Normalizing RT file for {sample_name}\", check=False)\n",
    "        \n",
    "        # RBRPスコア計算\n",
    "        rbrp_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_rbrp.out\"\n",
    "        background_file = merged_control if 'merged_control' in locals() else None\n",
    "        \n",
    "        if background_file and background_file.exists():\n",
    "            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n",
    "                          -f {normalized_file} -b {background_file} -o {rbrp_file} \\\n",
    "                          -e dividing -y 0.5\"\"\"\n",
    "        else:\n",
    "            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n",
    "                          -f {normalized_file} -o {rbrp_file}\"\"\"\n",
    "        \n",
    "        run_command(rbrp_cmd, f\"Calculating RBRP scores for {sample_name}\", check=False)\n",
    "        \n",
    "        # 低品質スコアフィルタリング\n",
    "        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        filter_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/filter_rbrp_scores.py \\\n",
    "                        -i {rbrp_file} -o {filtered_file} \\\n",
    "                        -t {ANALYSIS_PARAMS['min_sequencing_depth']} -s 5 -e 30\"\"\"\n",
    "        run_command(filter_cmd, f\"Filtering RBRP scores for {sample_name}\", check=False)\n",
    "        \n",
    "        logger.info(f\"✅ {sample_name}: RBRPスコア計算完了\")\n",
    "    \n",
    "    print(\"✅ ステップ4完了: RBRPスコア計算・統計解析\")\n",
    "\n",
    "step4_rbrp_score_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ステップ5: 可視化ファイル生成・結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step5_visualization_and_output():\n",
    "    \"\"\"ステップ5: 可視化ファイル生成と結果出力\"\"\"\n",
    "    print(\"\\n📈 ステップ5: 可視化ファイル生成・結果出力開始\")\n",
    "    \n",
    "    for sample_name in tqdm(probe_samples, desc=\"Generating visualization files\"):\n",
    "        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        \n",
    "        if not filtered_file.exists():\n",
    "            logger.warning(f\"⚠️ フィルタリング済みファイルが見つかりません: {filtered_file}\")\n",
    "            continue\n",
    "        \n",
    "        # bedgraphファイル生成\n",
    "        bedgraph_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bedgraph\"\n",
    "        bedgraph_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/generate_bedgraph.py \\\n",
    "                          -i {filtered_file} -o {bedgraph_file} \\\n",
    "                          -g {REFERENCE_FILES['genome_gtf']} \\\n",
    "                          -a {REFERENCE_FILES.get('transcriptome_fasta', '')}\"\"\"\n",
    "        run_command(bedgraph_cmd, f\"Generating bedgraph for {sample_name}\", check=False)\n",
    "        \n",
    "        # bigwigファイル生成（UCscツールが利用可能な場合）\n",
    "        bigwig_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bw\"\n",
    "        genome_size_file = PROJECT_ROOT / \"data/genome.size\"  # 事前に準備が必要\n",
    "        \n",
    "        if bedgraph_file.exists():\n",
    "            # ソートと重複除去\n",
    "            sorted_bedgraph = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}_sorted.bedgraph\"\n",
    "            sort_cmd = f\"sort -k1,1 -k2,3n {bedgraph_file} | uniq > {sorted_bedgraph}\"\n",
    "            run_command(sort_cmd, f\"Sorting bedgraph for {sample_name}\", check=False)\n",
    "            \n",
    "            # bigwig変換\n",
    "            if genome_size_file.exists():\n",
    "                bw_cmd = f\"bedGraphToBigWig {sorted_bedgraph} {genome_size_file} {bigwig_file}\"\n",
    "                run_command(bw_cmd, f\"Converting to bigwig for {sample_name}\", check=False)\n",
    "        \n",
    "        logger.info(f\"✅ {sample_name}: 可視化ファイル生成完了\")\n",
    "    \n",
    "    print(\"✅ ステップ5完了: 可視化ファイル生成・結果出力\")\n",
    "\n",
    "step5_visualization_and_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 結果サマリー・統計情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report():\n",
    "    \"\"\"結果サマリーレポート生成\"\"\"\n",
    "    print(\"\\n📋 結果サマリーレポート生成\")\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for sample_name in INPUT_FASTQ_FILES.keys():\n",
    "        sample_summary = {'sample_name': sample_name}\n",
    "        \n",
    "        # 各ステップのファイル存在確認\n",
    "        files_to_check = {\n",
    "            'demultiplexed': f\"data/processed/{sample_name}_demux.fastq\",\n",
    "            'trimmed': f\"data/processed/trimmed/{sample_name}_trimmed.fastq\",\n",
    "            'aligned': f\"data/processed/aligned/{sample_name}.sam\",\n",
    "            'rbrp_scores': f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        }\n",
    "        \n",
    "        for step, file_path in files_to_check.items():\n",
    "            full_path = PROJECT_ROOT / file_path\n",
    "            sample_summary[f'{step}_exists'] = full_path.exists()\n",
    "            if full_path.exists():\n",
    "                sample_summary[f'{step}_size_mb'] = round(full_path.stat().st_size / 1024 / 1024, 2)\n",
    "        \n",
    "        summary_data.append(sample_summary)\n",
    "    \n",
    "    # サマリーDataFrame作成\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # 結果表示\n",
    "    print(\"\\n📊 処理結果サマリー:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # CSVファイルとして保存\n",
    "    summary_file = PROJECT_ROOT / \"data/results/processing_summary.csv\"\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    # 統計情報\n",
    "    successful_samples = summary_df['rbrp_scores_exists'].sum()\n",
    "    total_samples = len(summary_df)\n",
    "    \n",
    "    print(f\"\\n📈 処理統計:\")\n",
    "    print(f\"   総サンプル数: {total_samples}\")\n",
    "    print(f\"   成功サンプル数: {successful_samples}\")\n",
    "    print(f\"   成功率: {successful_samples/total_samples*100:.1f}%\")\n",
    "    print(f\"   サマリーファイル: {summary_file}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "summary_report = generate_summary_report()\n",
    "\n",
    "# 実行時間の記録\n",
    "print(f\"\\n🎉 パイプライン実行完了!\")\n",
    "print(f\"📁 結果ファイルは以下に保存されました:\")\n",
    "print(f\"   - 処理済みデータ: {PROJECT_ROOT}/data/processed/\")\n",
    "print(f\"   - 最終結果: {PROJECT_ROOT}/data/results/\")\n",
    "print(f\"   - ログファイル: {log_file}\")\n",
    "\n",
    "logger.info(\"RBRP Dry Protocol Pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 結果可視化（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization_plots():\n",
    "    \"\"\"結果の可視化プロット作成\"\"\"\n",
    "    print(\"\\n📊 結果可視化プロット作成\")\n",
    "    \n",
    "    # 処理サマリーの可視化\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('RBRP Dry Protocol - 処理結果サマリー', fontsize=16, y=0.98)\n",
    "    \n",
    "    # 1. ファイルサイズ分布\n",
    "    size_columns = [col for col in summary_report.columns if 'size_mb' in col]\n",
    "    if size_columns:\n",
    "        size_data = summary_report[size_columns].fillna(0)\n",
    "        axes[0, 0].bar(range(len(size_columns)), size_data.mean(), \n",
    "                      tick_label=[col.replace('_size_mb', '') for col in size_columns])\n",
    "        axes[0, 0].set_title('平均ファイルサイズ (MB)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. 処理成功率\n",
    "    success_columns = [col for col in summary_report.columns if 'exists' in col]\n",
    "    if success_columns:\n",
    "        success_rates = summary_report[success_columns].mean() * 100\n",
    "        axes[0, 1].bar(range(len(success_rates)), success_rates.values,\n",
    "                      tick_label=[col.replace('_exists', '') for col in success_columns])\n",
    "        axes[0, 1].set_title('処理成功率 (%)')\n",
    "        axes[0, 1].set_ylim(0, 100)\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. サンプル別処理状況\n",
    "    if success_columns:\n",
    "        sample_success = summary_report[success_columns].sum(axis=1)\n",
    "        axes[1, 0].bar(range(len(sample_success)), sample_success.values,\n",
    "                      tick_label=summary_report['sample_name'])\n",
    "        axes[1, 0].set_title('サンプル別完了ステップ数')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. 処理時間の目安（仮想データ）\n",
    "    processing_steps = ['デマルチプレックス', 'トリミング', 'アライメント', 'RBRP計算', '可視化']\n",
    "    estimated_times = [5, 10, 30, 20, 5]  # 分単位\n",
    "    axes[1, 1].bar(processing_steps, estimated_times)\n",
    "    axes[1, 1].set_title('ステップ別推定処理時間 (分)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 図を保存\n",
    "    plot_file = PROJECT_ROOT / \"data/results/figures/processing_summary.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"📊 可視化プロット保存: {plot_file}\")\n",
    "\n",
    "# 可視化実行\n",
    "try:\n",
    "    create_visualization_plots()\n",
    "except Exception as e:\n",
    "    logger.warning(f\"可視化プロット作成エラー: {e}\")\n",
    "    print(\"⚠️ 可視化プロットの作成でエラーが発生しましたが、パイプライン自体は正常に完了しています\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
