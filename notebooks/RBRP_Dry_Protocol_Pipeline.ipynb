{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBRP Dry Protocol - ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹è§£æè‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Eric Koolãƒ©ãƒœã®è«–æ–‡ã€ŒReactivity-based RNA profiling for analyzing transcriptome interactions of small molecules in human cellsã€ã®ãƒ‰ãƒ©ã‚¤ãƒ—ãƒ­ãƒˆã‚³ãƒ«éƒ¨åˆ†ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "**å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼**: ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹åˆå­¦è€…  \n",
    "**å…¥åŠ›**: FASTQãƒ•ã‚¡ã‚¤ãƒ«  \n",
    "**å‡ºåŠ›**: RNA-è–¬ç‰©ç›¸äº’ä½œç”¨è§£æçµæœ\n",
    "\n",
    "## ä½¿ç”¨æ–¹æ³•\n",
    "1. è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
    "2. ã€ŒRun All Cellsã€ã§å…¨è‡ªå‹•å®Ÿè¡Œ\n",
    "3. çµæœã¯`data/results/`ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# ãƒ­ã‚°è¨­å®š\n",
    "log_file = PROJECT_ROOT / 'logs' / f'rbrp_pipeline_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"ğŸ§¬ RBRP Dry Protocol Pipeline Started\")\n",
    "print(f\"ğŸ“ Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"ğŸ“ Log File: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ãƒ»å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š =====\n",
    "# ã“ã“ã§å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„\n",
    "\n",
    "# å…¥åŠ›FASTQãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«å¯¾å¿œï¼‰\n",
    "INPUT_FASTQ_FILES = {\n",
    "    'sample1_probe_only': '/path/to/sample1_probe_only.fastq',\n",
    "    'sample1_probe_drug': '/path/to/sample1_probe_drug.fastq',\n",
    "    'sample2_DMSO_ctrl': '/path/to/sample2_DMSO_ctrl.fastq',\n",
    "    'sample2_drug_ctrl': '/path/to/sample2_drug_ctrl.fastq'\n",
    "}\n",
    "\n",
    "# å‚ç…§ã‚²ãƒãƒ ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "REFERENCE_FILES = {\n",
    "    'genome_fasta': '/path/to/genome.fa',\n",
    "    'genome_gtf': '/path/to/genome.gtf',\n",
    "    'transcriptome_index': '/path/to/transcriptome_index',\n",
    "    'adapter_fasta': '/path/to/adapter.fa'\n",
    "}\n",
    "\n",
    "# ãƒãƒ¼ã‚³ãƒ¼ãƒ‰æƒ…å ±\n",
    "BARCODES = {\n",
    "    'sample1_probe_only': 'GGTT',\n",
    "    'sample1_probe_drug': 'TTGT', \n",
    "    'sample2_DMSO_ctrl': 'ACCT',\n",
    "    'sample2_drug_ctrl': 'CAAT'\n",
    "}\n",
    "\n",
    "# è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "ANALYSIS_PARAMS = {\n",
    "    'min_read_length': 25,\n",
    "    'min_rpkm': 1,\n",
    "    'min_sequencing_depth': 200,\n",
    "    'rbrp_score_threshold': 0.12,\n",
    "    'p_value_threshold': 0.05\n",
    "}\n",
    "\n",
    "print(\"âœ… è¨­å®šå®Œäº†\")\n",
    "print(f\"ğŸ“Š è§£æå¯¾è±¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(INPUT_FASTQ_FILES)}\")\n",
    "logger.info(f\"Analysis started with {len(INPUT_FASTQ_FILES)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ãƒ»å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_external_tools():\n",
    "    \"\"\"å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã®å­˜åœ¨ç¢ºèª\"\"\"\n",
    "    required_tools = [\n",
    "        'fastqc',\n",
    "        'bowtie2',\n",
    "        'gffread',\n",
    "        'wiggletools',\n",
    "        'bedGraphToBigWig',\n",
    "        'wigToBigWig'\n",
    "    ]\n",
    "    \n",
    "    missing_tools = []\n",
    "    \n",
    "    for tool in required_tools:\n",
    "        try:\n",
    "            result = subprocess.run(['which', tool], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"âœ… {tool}: {result.stdout.strip()}\")\n",
    "            else:\n",
    "                missing_tools.append(tool)\n",
    "                print(f\"âŒ {tool}: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        except Exception as e:\n",
    "            missing_tools.append(tool)\n",
    "            print(f\"âŒ {tool}: ã‚¨ãƒ©ãƒ¼ - {e}\")\n",
    "    \n",
    "    if missing_tools:\n",
    "        print(f\"\\nâš ï¸ ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_tools)}\")\n",
    "        print(\"ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã¯README.mdã‚’å‚ç…§ã—ã¦ãã ã•ã„\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\nğŸ‰ ã™ã¹ã¦ã®å¿…è¦ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™\")\n",
    "        return True\n",
    "\n",
    "tools_available = check_external_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ç¾¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(cmd, description, check=True):\n",
    "    \"\"\"ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\"\"\"\n",
    "    logger.info(f\"å®Ÿè¡Œä¸­: {description}\")\n",
    "    logger.debug(f\"ã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=check, \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            logger.info(f\"âœ… å®Œäº†: {description}\")\n",
    "            return result\n",
    "        else:\n",
    "            logger.error(f\"âŒ å¤±æ•—: {description}\")\n",
    "            logger.error(f\"ã‚¨ãƒ©ãƒ¼å‡ºåŠ›: {result.stderr}\")\n",
    "            if check:\n",
    "                raise subprocess.CalledProcessError(result.returncode, cmd)\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"âŒ ä¾‹å¤–ç™ºç”Ÿ: {description} - {e}\")\n",
    "        if check:\n",
    "            raise\n",
    "        return None\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\"\"\"\n",
    "    dirs = [\n",
    "        'data/processed/fastqc',\n",
    "        'data/processed/trimmed', \n",
    "        'data/processed/aligned',\n",
    "        'data/processed/rbrp_scores',\n",
    "        'data/results/bigwig',\n",
    "        'data/results/figures'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        (PROJECT_ROOT / dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logger.info(\"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ\")\n",
    "\n",
    "create_output_dirs()\n",
    "print(\"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ã‚¹ãƒ†ãƒƒãƒ—1: å“è³ªç®¡ç†ãƒ»ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_quality_control_and_demultiplex():\n",
    "    \"\"\"ã‚¹ãƒ†ãƒƒãƒ—1: å“è³ªç®¡ç†ã¨ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹\"\"\"\n",
    "    print(\"\\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—1: å“è³ªç®¡ç†ãƒ»ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹é–‹å§‹\")\n",
    "    \n",
    "    for sample_name, fastq_path in tqdm(INPUT_FASTQ_FILES.items(), desc=\"Processing samples\"):\n",
    "        if not Path(fastq_path).exists():\n",
    "            logger.warning(f\"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fastq_path}\")\n",
    "            continue\n",
    "            \n",
    "        # FastQCå®Ÿè¡Œ\n",
    "        fastqc_cmd = f\"fastqc -o {PROJECT_ROOT}/data/processed/fastqc {fastq_path}\"\n",
    "        run_command(fastqc_cmd, f\"FastQC for {sample_name}\")\n",
    "        \n",
    "        # ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹ï¼ˆãƒãƒ¼ã‚³ãƒ¼ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰\n",
    "        if sample_name in BARCODES:\n",
    "            barcode = BARCODES[sample_name]\n",
    "            output_file = PROJECT_ROOT / f\"data/processed/{sample_name}_demux.fastq\"\n",
    "            \n",
    "            # ç°¡å˜ãªãƒãƒ¼ã‚³ãƒ¼ãƒ‰æŠ½å‡ºï¼ˆå®Ÿéš›ã®splitFastq.plã®ä»£æ›¿ï¼‰\n",
    "            demux_cmd = f\"\"\"grep -A 3 \"^@.*{barcode}\" {fastq_path} | grep -v \"^--$\" > {output_file}\"\"\"\n",
    "            run_command(demux_cmd, f\"Demultiplexing {sample_name}\", check=False)\n",
    "            \n",
    "            logger.info(f\"âœ… {sample_name}: ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹å®Œäº†\")\n",
    "    \n",
    "    print(\"âœ… ã‚¹ãƒ†ãƒƒãƒ—1å®Œäº†: å“è³ªç®¡ç†ãƒ»ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹\")\n",
    "\n",
    "step1_quality_control_and_demultiplex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ã‚¹ãƒ†ãƒƒãƒ—2: PCRé‡è¤‡é™¤å»ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_remove_duplicates_and_trim():\n",
    "    \"\"\"ã‚¹ãƒ†ãƒƒãƒ—2: PCRé‡è¤‡é™¤å»ã¨ãƒˆãƒªãƒŸãƒ³ã‚°\"\"\"\n",
    "    print(\"\\nâœ‚ï¸ ã‚¹ãƒ†ãƒƒãƒ—2: PCRé‡è¤‡é™¤å»ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°é–‹å§‹\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing trimming\"):\n",
    "        input_file = PROJECT_ROOT / f\"data/processed/{sample_name}_demux.fastq\"\n",
    "        \n",
    "        if not input_file.exists():\n",
    "            logger.warning(f\"âš ï¸ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}\")\n",
    "            continue\n",
    "        \n",
    "        # PCRé‡è¤‡é™¤å»ï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
    "        rmdup_file = PROJECT_ROOT / f\"data/processed/{sample_name}_rmdup.fastq\"\n",
    "        rmdup_cmd = f\"\"\"awk '/^@/ {{if (seen[$0]++) next}} 1' {input_file} > {rmdup_file}\"\"\"\n",
    "        run_command(rmdup_cmd, f\"Remove duplicates for {sample_name}\")\n",
    "        \n",
    "        # ãƒˆãƒªãƒŸãƒ³ã‚°\n",
    "        trimmed_file = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed.fastq\"\n",
    "        \n",
    "        # ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼é…åˆ—é™¤å»ã¨ã‚¯ã‚ªãƒªãƒ†ã‚£ãƒˆãƒªãƒŸãƒ³ã‚°\n",
    "        trim_cmd = f\"\"\"cutadapt -a AGATCGGAAGAGCGGTTCAG -q 30 -m {ANALYSIS_PARAMS['min_read_length']} \\\n",
    "                     -o {trimmed_file} {rmdup_file}\"\"\"\n",
    "        \n",
    "        run_command(trim_cmd, f\"Trimming adapters for {sample_name}\", check=False)\n",
    "        logger.info(f\"âœ… {sample_name}: ãƒˆãƒªãƒŸãƒ³ã‚°å®Œäº†\")\n",
    "    \n",
    "    print(\"âœ… ã‚¹ãƒ†ãƒƒãƒ—2å®Œäº†: PCRé‡è¤‡é™¤å»ãƒ»ãƒˆãƒªãƒŸãƒ³ã‚°\")\n",
    "\n",
    "step2_remove_duplicates_and_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ã‚¹ãƒ†ãƒƒãƒ—3: é…åˆ—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»è»¢å†™ç”£ç‰©ç™ºç¾é‡è¨ˆç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_alignment_and_expression():\n",
    "    \"\"\"ã‚¹ãƒ†ãƒƒãƒ—3: é…åˆ—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨è»¢å†™ç”£ç‰©ç™ºç¾é‡è¨ˆç®—\"\"\"\n",
    "    print(\"\\nğŸ§¬ ã‚¹ãƒ†ãƒƒãƒ—3: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»ç™ºç¾é‡è¨ˆç®—é–‹å§‹\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing alignment\"):\n",
    "        trimmed_file = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed.fastq\"\n",
    "        \n",
    "        if not trimmed_file.exists():\n",
    "            logger.warning(f\"âš ï¸ ãƒˆãƒªãƒŸãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {trimmed_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Bowtie2ã§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ\n",
    "        sam_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.sam\"\n",
    "        \n",
    "        align_cmd = f\"\"\"bowtie2 -U {trimmed_file} -S {sam_file} \\\n",
    "                       -x {REFERENCE_FILES['transcriptome_index']} \\\n",
    "                       --non-deterministic --time\"\"\"\n",
    "        \n",
    "        run_command(align_cmd, f\"Alignment for {sample_name}\")\n",
    "        \n",
    "        # RPKMè¨ˆç®—\n",
    "        rpkm_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rpkm\"\n",
    "        rpkm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rpkm.py -i {sam_file} -o {rpkm_file}\"\"\"\n",
    "        \n",
    "        run_command(rpkm_cmd, f\"RPKM calculation for {sample_name}\", check=False)\n",
    "        \n",
    "        # RTstopè¨ˆç®—\n",
    "        rt_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        rt_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rtstops.py \\\n",
    "                    -i {sam_file} -o {rt_file} -r {rpkm_file} -c {ANALYSIS_PARAMS['min_rpkm']}\"\"\"\n",
    "        \n",
    "        run_command(rt_cmd, f\"RTstop calculation for {sample_name}\", check=False)\n",
    "        logger.info(f\"âœ… {sample_name}: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»ç™ºç¾é‡è¨ˆç®—å®Œäº†\")\n",
    "    \n",
    "    print(\"âœ… ã‚¹ãƒ†ãƒƒãƒ—3å®Œäº†: ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»ç™ºç¾é‡è¨ˆç®—\")\n",
    "\n",
    "step3_alignment_and_expression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ã‚¹ãƒ†ãƒƒãƒ—4: RBRPã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ»çµ±è¨ˆè§£æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_rbrp_score_calculation():\n",
    "    \"\"\"ã‚¹ãƒ†ãƒƒãƒ—4: RBRPã‚¹ã‚³ã‚¢è¨ˆç®—ã¨çµ±è¨ˆè§£æ\"\"\"\n",
    "    print(\"\\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—4: RBRPã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ»çµ±è¨ˆè§£æé–‹å§‹\")\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘\n",
    "    probe_samples = [k for k in INPUT_FASTQ_FILES.keys() if 'probe' in k]\n",
    "    control_samples = [k for k in INPUT_FASTQ_FILES.keys() if 'ctrl' in k or 'DMSO' in k]\n",
    "    \n",
    "    print(f\"ğŸ“‹ ãƒ—ãƒ­ãƒ¼ãƒ–ã‚µãƒ³ãƒ—ãƒ«: {probe_samples}\")\n",
    "    print(f\"ğŸ“‹ ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚µãƒ³ãƒ—ãƒ«: {control_samples}\")\n",
    "    \n",
    "    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰RTstopãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸\n",
    "    if len(control_samples) >= 2:\n",
    "        control_files = [f\"{PROJECT_ROOT}/data/processed/aligned/{s}.rt\" for s in control_samples]\n",
    "        merged_control = PROJECT_ROOT / \"data/processed/rbrp_scores/merged_control.rt\"\n",
    "        \n",
    "        merge_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/merge_rt_files.py \\\n",
    "                       -i {':'.join(control_files)} -o {merged_control}\"\"\"\n",
    "        run_command(merge_cmd, \"Merging control RTstop files\", check=False)\n",
    "    \n",
    "    # å„ãƒ—ãƒ­ãƒ¼ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã®RBRPã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "    for sample_name in tqdm(probe_samples, desc=\"Calculating RBRP scores\"):\n",
    "        rt_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        \n",
    "        if not rt_file.exists():\n",
    "            logger.warning(f\"âš ï¸ RTãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {rt_file}\")\n",
    "            continue\n",
    "        \n",
    "        # RTãƒ•ã‚¡ã‚¤ãƒ«æ­£è¦åŒ–\n",
    "        normalized_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_normalized.rt\"\n",
    "        norm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/normalize_rt_file.py \\\n",
    "                      -i {rt_file} -o {normalized_file} -d 32 -l 32\"\"\"\n",
    "        run_command(norm_cmd, f\"Normalizing RT file for {sample_name}\", check=False)\n",
    "        \n",
    "        # RBRPã‚¹ã‚³ã‚¢è¨ˆç®—\n",
    "        rbrp_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_rbrp.out\"\n",
    "        background_file = merged_control if 'merged_control' in locals() else None\n",
    "        \n",
    "        if background_file and background_file.exists():\n",
    "            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n",
    "                          -f {normalized_file} -b {background_file} -o {rbrp_file} \\\n",
    "                          -e dividing -y 0.5\"\"\"\n",
    "        else:\n",
    "            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n",
    "                          -f {normalized_file} -o {rbrp_file}\"\"\"\n",
    "        \n",
    "        run_command(rbrp_cmd, f\"Calculating RBRP scores for {sample_name}\", check=False)\n",
    "        \n",
    "        # ä½å“è³ªã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        filter_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/filter_rbrp_scores.py \\\n",
    "                        -i {rbrp_file} -o {filtered_file} \\\n",
    "                        -t {ANALYSIS_PARAMS['min_sequencing_depth']} -s 5 -e 30\"\"\"\n",
    "        run_command(filter_cmd, f\"Filtering RBRP scores for {sample_name}\", check=False)\n",
    "        \n",
    "        logger.info(f\"âœ… {sample_name}: RBRPã‚¹ã‚³ã‚¢è¨ˆç®—å®Œäº†\")\n",
    "    \n",
    "    print(\"âœ… ã‚¹ãƒ†ãƒƒãƒ—4å®Œäº†: RBRPã‚¹ã‚³ã‚¢è¨ˆç®—ãƒ»çµ±è¨ˆè§£æ\")\n",
    "\n",
    "step4_rbrp_score_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ»çµæœå‡ºåŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step5_visualization_and_output():\n",
    "    \"\"\"ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã¨çµæœå‡ºåŠ›\"\"\"\n",
    "    print(\"\\nğŸ“ˆ ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ»çµæœå‡ºåŠ›é–‹å§‹\")\n",
    "    \n",
    "    for sample_name in tqdm(probe_samples, desc=\"Generating visualization files\"):\n",
    "        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        \n",
    "        if not filtered_file.exists():\n",
    "            logger.warning(f\"âš ï¸ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filtered_file}\")\n",
    "            continue\n",
    "        \n",
    "        # bedgraphãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ\n",
    "        bedgraph_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bedgraph\"\n",
    "        bedgraph_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/generate_bedgraph.py \\\n",
    "                          -i {filtered_file} -o {bedgraph_file} \\\n",
    "                          -g {REFERENCE_FILES['genome_gtf']} \\\n",
    "                          -a {REFERENCE_FILES.get('transcriptome_fasta', '')}\"\"\"\n",
    "        run_command(bedgraph_cmd, f\"Generating bedgraph for {sample_name}\", check=False)\n",
    "        \n",
    "        # bigwigãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆUCscãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
    "        bigwig_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bw\"\n",
    "        genome_size_file = PROJECT_ROOT / \"data/genome.size\"  # äº‹å‰ã«æº–å‚™ãŒå¿…è¦\n",
    "        \n",
    "        if bedgraph_file.exists():\n",
    "            # ã‚½ãƒ¼ãƒˆã¨é‡è¤‡é™¤å»\n",
    "            sorted_bedgraph = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}_sorted.bedgraph\"\n",
    "            sort_cmd = f\"sort -k1,1 -k2,3n {bedgraph_file} | uniq > {sorted_bedgraph}\"\n",
    "            run_command(sort_cmd, f\"Sorting bedgraph for {sample_name}\", check=False)\n",
    "            \n",
    "            # bigwigå¤‰æ›\n",
    "            if genome_size_file.exists():\n",
    "                bw_cmd = f\"bedGraphToBigWig {sorted_bedgraph} {genome_size_file} {bigwig_file}\"\n",
    "                run_command(bw_cmd, f\"Converting to bigwig for {sample_name}\", check=False)\n",
    "        \n",
    "        logger.info(f\"âœ… {sample_name}: å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†\")\n",
    "    \n",
    "    print(\"âœ… ã‚¹ãƒ†ãƒƒãƒ—5å®Œäº†: å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆãƒ»çµæœå‡ºåŠ›\")\n",
    "\n",
    "step5_visualization_and_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. çµæœã‚µãƒãƒªãƒ¼ãƒ»çµ±è¨ˆæƒ…å ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report():\n",
    "    \"\"\"çµæœã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\"\"\"\n",
    "    print(\"\\nğŸ“‹ çµæœã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ\")\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for sample_name in INPUT_FASTQ_FILES.keys():\n",
    "        sample_summary = {'sample_name': sample_name}\n",
    "        \n",
    "        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª\n",
    "        files_to_check = {\n",
    "            'demultiplexed': f\"data/processed/{sample_name}_demux.fastq\",\n",
    "            'trimmed': f\"data/processed/trimmed/{sample_name}_trimmed.fastq\",\n",
    "            'aligned': f\"data/processed/aligned/{sample_name}.sam\",\n",
    "            'rbrp_scores': f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        }\n",
    "        \n",
    "        for step, file_path in files_to_check.items():\n",
    "            full_path = PROJECT_ROOT / file_path\n",
    "            sample_summary[f'{step}_exists'] = full_path.exists()\n",
    "            if full_path.exists():\n",
    "                sample_summary[f'{step}_size_mb'] = round(full_path.stat().st_size / 1024 / 1024, 2)\n",
    "        \n",
    "        summary_data.append(sample_summary)\n",
    "    \n",
    "    # ã‚µãƒãƒªãƒ¼DataFrameä½œæˆ\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # çµæœè¡¨ç¤º\n",
    "    print(\"\\nğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "    summary_file = PROJECT_ROOT / \"data/results/processing_summary.csv\"\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±\n",
    "    successful_samples = summary_df['rbrp_scores_exists'].sum()\n",
    "    total_samples = len(summary_df)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å‡¦ç†çµ±è¨ˆ:\")\n",
    "    print(f\"   ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {total_samples}\")\n",
    "    print(f\"   æˆåŠŸã‚µãƒ³ãƒ—ãƒ«æ•°: {successful_samples}\")\n",
    "    print(f\"   æˆåŠŸç‡: {successful_samples/total_samples*100:.1f}%\")\n",
    "    print(f\"   ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«: {summary_file}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "summary_report = generate_summary_report()\n",
    "\n",
    "# å®Ÿè¡Œæ™‚é–“ã®è¨˜éŒ²\n",
    "print(f\"\\nğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†!\")\n",
    "print(f\"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ:\")\n",
    "print(f\"   - å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿: {PROJECT_ROOT}/data/processed/\")\n",
    "print(f\"   - æœ€çµ‚çµæœ: {PROJECT_ROOT}/data/results/\")\n",
    "print(f\"   - ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_file}\")\n",
    "\n",
    "logger.info(\"RBRP Dry Protocol Pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. çµæœå¯è¦–åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization_plots():\n",
    "    \"\"\"çµæœã®å¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ\"\"\"\n",
    "    print(\"\\nğŸ“Š çµæœå¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ\")\n",
    "    \n",
    "    # å‡¦ç†ã‚µãƒãƒªãƒ¼ã®å¯è¦–åŒ–\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('RBRP Dry Protocol - å‡¦ç†çµæœã‚µãƒãƒªãƒ¼', fontsize=16, y=0.98)\n",
    "    \n",
    "    # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†å¸ƒ\n",
    "    size_columns = [col for col in summary_report.columns if 'size_mb' in col]\n",
    "    if size_columns:\n",
    "        size_data = summary_report[size_columns].fillna(0)\n",
    "        axes[0, 0].bar(range(len(size_columns)), size_data.mean(), \n",
    "                      tick_label=[col.replace('_size_mb', '') for col in size_columns])\n",
    "        axes[0, 0].set_title('å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º (MB)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. å‡¦ç†æˆåŠŸç‡\n",
    "    success_columns = [col for col in summary_report.columns if 'exists' in col]\n",
    "    if success_columns:\n",
    "        success_rates = summary_report[success_columns].mean() * 100\n",
    "        axes[0, 1].bar(range(len(success_rates)), success_rates.values,\n",
    "                      tick_label=[col.replace('_exists', '') for col in success_columns])\n",
    "        axes[0, 1].set_title('å‡¦ç†æˆåŠŸç‡ (%)')\n",
    "        axes[0, 1].set_ylim(0, 100)\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. ã‚µãƒ³ãƒ—ãƒ«åˆ¥å‡¦ç†çŠ¶æ³\n",
    "    if success_columns:\n",
    "        sample_success = summary_report[success_columns].sum(axis=1)\n",
    "        axes[1, 0].bar(range(len(sample_success)), sample_success.values,\n",
    "                      tick_label=summary_report['sample_name'])\n",
    "        axes[1, 0].set_title('ã‚µãƒ³ãƒ—ãƒ«åˆ¥å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—æ•°')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. å‡¦ç†æ™‚é–“ã®ç›®å®‰ï¼ˆä»®æƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰\n",
    "    processing_steps = ['ãƒ‡ãƒãƒ«ãƒãƒ—ãƒ¬ãƒƒã‚¯ã‚¹', 'ãƒˆãƒªãƒŸãƒ³ã‚°', 'ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ', 'RBRPè¨ˆç®—', 'å¯è¦–åŒ–']\n",
    "    estimated_times = [5, 10, 30, 20, 5]  # åˆ†å˜ä½\n",
    "    axes[1, 1].bar(processing_steps, estimated_times)\n",
    "    axes[1, 1].set_title('ã‚¹ãƒ†ãƒƒãƒ—åˆ¥æ¨å®šå‡¦ç†æ™‚é–“ (åˆ†)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # å›³ã‚’ä¿å­˜\n",
    "    plot_file = PROJECT_ROOT / \"data/results/figures/processing_summary.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ğŸ“Š å¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {plot_file}\")\n",
    "\n",
    "# å¯è¦–åŒ–å®Ÿè¡Œ\n",
    "try:\n",
    "    create_visualization_plots()\n",
    "except Exception as e:\n",
    "    logger.warning(f\"å¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "    print(\"âš ï¸ å¯è¦–åŒ–ãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãŒã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªä½“ã¯æ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã¾ã™\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
