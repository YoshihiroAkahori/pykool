{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBRP Dry Protocol - バイオインフォマティクス解析自動化パイプライン\n",
    "\n",
    "このノートブックは、Eric Koolラボの論文「Reactivity-based RNA profiling for analyzing transcriptome interactions of small molecules in human cells」のドライプロトコル部分を自動化します。\n",
    "\n",
    "**対象ユーザー**: バイオインフォマティクス初学者  \n",
    "**入力**: FASTQファイル（ペアエンド対応）  \n",
    "**出力**: RNA-薬物相互作用解析結果\n",
    "\n",
    "## 🔧 モダンシーケンサー対応\n",
    "最近のシーケンサー（Illumina NovaSeq、NextSeq等）では以下の処理が自動で実行されるため、スキップオプションを用意しています：\n",
    "\n",
    "- **デマルチプレックス**: バーコード分離済みFASTQファイルの出力\n",
    "- **アダプタートリミング**: アダプター配列除去済みの出力\n",
    "- **品質フィルタリング**: 低品質リード除去済みの出力\n",
    "\n",
    "デフォルト設定では、これらの処理をスキップして高速化されています。\n",
    "\n",
    "## 使用方法\n",
    "1. 設定セクションで入力ファイルパスを指定\n",
    "2. スキップオプションを必要に応じて調整\n",
    "3. 「Run All Cells」で全自動実行\n",
    "4. 結果は`data/results/`フォルダに保存されます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定と初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧬 RBRP Dry Protocol Pipeline Started\n",
      "📁 Project Root: /home/akahod3f/work/kool\n",
      "📝 Log File: /home/akahod3f/work/kool/logs/rbrp_pipeline_20250917_044525.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# プロジェクトルートディレクトリを設定\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "sys.path.append(str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# ログ設定\n",
    "log_file = PROJECT_ROOT / 'logs' / f'rbrp_pipeline_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"🧬 RBRP Dry Protocol Pipeline Started\")\n",
    "print(f\"📁 Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"📝 Log File: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 設定ファイル読み込み・入力ファイル指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ===== ユーザー設定 =====\n# ここで入力ファイルを指定してください\n\n# 入力FASTQファイルのパス（ペアエンド対応）\n# Kool論文のSRA accession numbers (GSE229331) をデフォルトに使用\n# download_rbrp_data.pyでダウンロードした場合のデフォルトパス（data/raw）\nINPUT_FASTQ_FILES = {\n    'SRR22397001': {  # HEK293_Probe2_only_rep1\n        'R1': 'data/raw/SRR22397001_1.fastq',\n        'R2': 'data/raw/SRR22397001_2.fastq'\n    },\n    'SRR22397002': {  # HEK293_Probe2_only_rep2\n        'R1': 'data/raw/SRR22397002_1.fastq',\n        'R2': 'data/raw/SRR22397002_2.fastq'\n    },\n    'SRR22397003': {  # HEK293_Probe2_Levofloxacin_rep1\n        'R1': 'data/raw/SRR22397003_1.fastq',\n        'R2': 'data/raw/SRR22397003_2.fastq'\n    },\n    'SRR22397004': {  # HEK293_Probe2_Levofloxacin_rep2\n        'R1': 'data/raw/SRR22397004_1.fastq',\n        'R2': 'data/raw/SRR22397004_2.fastq'\n    },\n    'SRR22397005': {  # HEK293_DMSO_ctrl_rep1\n        'R1': 'data/raw/SRR22397005_1.fastq',\n        'R2': 'data/raw/SRR22397005_2.fastq'\n    },\n    'SRR22397006': {  # HEK293_DMSO_ctrl_rep2\n        'R1': 'data/raw/SRR22397006_1.fastq',\n        'R2': 'data/raw/SRR22397006_2.fastq'\n    },\n    'SRR22397007': {  # HEK293_Levofloxacin_ctrl_rep1\n        'R1': 'data/raw/SRR22397007_1.fastq',\n        'R2': 'data/raw/SRR22397007_2.fastq'\n    },\n    'SRR22397008': {  # HEK293_Levofloxacin_ctrl_rep2\n        'R1': 'data/raw/SRR22397008_1.fastq',\n        'R2': 'data/raw/SRR22397008_2.fastq'\n    }\n}\n\n# 参照ゲノムファイル\nREFERENCE_FILES = {\n    'genome_fasta': '/path/to/genome.fa',\n    'genome_gtf': '/path/to/genome.gtf',\n    'transcriptome_index': '/path/to/transcriptome_index',\n    'adapter_fasta': '/path/to/adapter.fa'\n}\n\n# バーコード情報（demultiplexをスキップしない場合のみ使用）\nBARCODES = {\n    'SRR22397001': 'GGTT',  # HEK293_Probe2_only_rep1\n    'SRR22397002': 'TTGT',  # HEK293_Probe2_only_rep2\n    'SRR22397003': 'ACCT',  # HEK293_Probe2_Levofloxacin_rep1\n    'SRR22397004': 'CAAT',  # HEK293_Probe2_Levofloxacin_rep2\n    'SRR22397005': 'GCAA',  # HEK293_DMSO_ctrl_rep1\n    'SRR22397006': 'AATC',  # HEK293_DMSO_ctrl_rep2\n    'SRR22397007': 'TGAC',  # HEK293_Levofloxacin_ctrl_rep1\n    'SRR22397008': 'CGGT'   # HEK293_Levofloxacin_ctrl_rep2\n}\n\n# 解析パラメータ\nANALYSIS_PARAMS = {\n    'min_read_length': 25,\n    'min_rpkm': 1,\n    'min_sequencing_depth': 200,\n    'rbrp_score_threshold': 0.12,\n    'p_value_threshold': 0.05\n}\n\n# 🔧 処理スキップオプション\nPROCESSING_OPTIONS = {\n    'skip_demultiplex': True,            # True: デマルチプレックスをスキップ\n    'skip_adapter_trimming': True,       # True: アダプタートリミングをスキップ\n    'skip_pcr_duplicate_removal': False, # True: PCR重複除去をスキップ\n    'perform_quality_control': False,    # True: FastQCによる品質確認を実行\n    'adapter_sequences': {               # カスタムアダプター配列（trimming実行時のみ使用）\n        'R1': 'AGATCGGAAGAGCGGTTCAG',\n        'R2': 'AGATCGGAAGAGCGGTTCAG'\n    }\n}\n\nprint(\"✅ 設定完了（SRA accession numbers使用・data/rawディレクトリ・ペアエンド対応・スキップオプション付き）\")\nprint(f\"📊 解析対象サンプル数: {len(INPUT_FASTQ_FILES)}\")\nprint(f\"📁 入力ディレクトリ: data/raw (download_rbrp_data.pyのデフォルト)\")\nprint(f\"🔧 デマルチプレックススキップ: {PROCESSING_OPTIONS['skip_demultiplex']}\")\nprint(f\"🔧 アダプタートリミングスキップ: {PROCESSING_OPTIONS['skip_adapter_trimming']}\")\nlogger.info(f\"Analysis started with {len(INPUT_FASTQ_FILES)} paired-end samples from Kool lab (GSE229331) in data/raw\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 依存関係チェック・外部ツール確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_external_tools():\n",
    "    \"\"\"外部ツールの存在確認\"\"\"\n",
    "    required_tools = [\n",
    "        'fastqc',\n",
    "        'bowtie2',\n",
    "        'gffread',\n",
    "        'wiggletools',\n",
    "        'bedGraphToBigWig',\n",
    "        'wigToBigWig'\n",
    "    ]\n",
    "    \n",
    "    missing_tools = []\n",
    "    \n",
    "    for tool in required_tools:\n",
    "        try:\n",
    "            result = subprocess.run(['which', tool], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"✅ {tool}: {result.stdout.strip()}\")\n",
    "            else:\n",
    "                missing_tools.append(tool)\n",
    "                print(f\"❌ {tool}: 見つかりません\")\n",
    "        except Exception as e:\n",
    "            missing_tools.append(tool)\n",
    "            print(f\"❌ {tool}: エラー - {e}\")\n",
    "    \n",
    "    if missing_tools:\n",
    "        print(f\"\\n⚠️ 以下のツールが不足しています: {', '.join(missing_tools)}\")\n",
    "        print(\"インストール方法はREADME.mdを参照してください\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n🎉 すべての必要ツールが利用可能です\")\n",
    "        return True\n",
    "\n",
    "tools_available = check_external_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. パイプライン実行関数群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(cmd, description, check=True):\n",
    "    \"\"\"コマンド実行のヘルパー関数\"\"\"\n",
    "    logger.info(f\"実行中: {description}\")\n",
    "    logger.debug(f\"コマンド: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=check, \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            logger.info(f\"✅ 完了: {description}\")\n",
    "            return result\n",
    "        else:\n",
    "            logger.error(f\"❌ 失敗: {description}\")\n",
    "            logger.error(f\"エラー出力: {result.stderr}\")\n",
    "            if check:\n",
    "                raise subprocess.CalledProcessError(result.returncode, cmd)\n",
    "            return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ 例外発生: {description} - {e}\")\n",
    "        if check:\n",
    "            raise\n",
    "        return None\n",
    "\n",
    "def find_latest_processed_files(sample_name, file_type=\"fastq\"):\n",
    "    \"\"\"\n",
    "    サンプルの最新処理済みファイルを動的に検索\n",
    "    \n",
    "    Args:\n",
    "        sample_name (str): サンプル名\n",
    "        file_type (str): ファイルタイプ (\"fastq\", \"sam\", \"rt\" など)\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\"R1\": path, \"R2\": path} または None\n",
    "    \"\"\"\n",
    "    search_patterns = {\n",
    "        \"fastq\": [\n",
    "            f\"data/processed/trimmed/{sample_name}_trimmed\",  # トリミング済み\n",
    "            f\"data/processed/{sample_name}_rmdup\",            # PCR重複除去済み\n",
    "            f\"data/processed/{sample_name}_demux\",            # デマルチプレックス済み\n",
    "        ],\n",
    "        \"sam\": [\n",
    "            f\"data/processed/aligned/{sample_name}.sam\"\n",
    "        ],\n",
    "        \"rt\": [\n",
    "            f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if file_type == \"fastq\":\n",
    "        # ペアエンドファイルの場合\n",
    "        for pattern in search_patterns[file_type]:\n",
    "            r1_file = PROJECT_ROOT / f\"{pattern}_1.fastq\"\n",
    "            r2_file = PROJECT_ROOT / f\"{pattern}_2.fastq\"\n",
    "            \n",
    "            if r1_file.exists() and r2_file.exists():\n",
    "                logger.info(f\"✅ {sample_name}: 使用ファイル {pattern}_*.fastq\")\n",
    "                return {\"R1\": r1_file, \"R2\": r2_file}\n",
    "        \n",
    "        # 最後の手段：元のFASTQファイル\n",
    "        original_r1 = INPUT_FASTQ_FILES[sample_name]['R1']\n",
    "        original_r2 = INPUT_FASTQ_FILES[sample_name]['R2']\n",
    "        if Path(original_r1).exists() and Path(original_r2).exists():\n",
    "            logger.warning(f\"⚠️ {sample_name}: 元ファイルを使用 {original_r1}, {original_r2}\")\n",
    "            return {\"R1\": Path(original_r1), \"R2\": Path(original_r2)}\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # 単一ファイルの場合\n",
    "        for pattern in search_patterns.get(file_type, []):\n",
    "            file_path = PROJECT_ROOT / pattern\n",
    "            if file_path.exists():\n",
    "                logger.info(f\"✅ {sample_name}: 使用ファイル {pattern}\")\n",
    "                return file_path\n",
    "        return None\n",
    "\n",
    "def create_output_dirs():\n",
    "    \"\"\"出力ディレクトリ作成\"\"\"\n",
    "    dirs = [\n",
    "        'logs',  # ログディレクトリを追加\n",
    "        'data/processed/fastqc',\n",
    "        'data/processed/trimmed', \n",
    "        'data/processed/aligned',\n",
    "        'data/processed/rbrp_scores',\n",
    "        'data/results/bigwig',\n",
    "        'data/results/figures'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in dirs:\n",
    "        (PROJECT_ROOT / dir_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    logger.info(\"📁 出力ディレクトリを作成しました\")\n",
    "\n",
    "create_output_dirs()\n",
    "print(\"📁 出力ディレクトリ準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ステップ1: 品質管理・デマルチプレックス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step1_quality_control_and_demultiplex():\n",
    "    \"\"\"ステップ1: 品質管理とデマルチプレックス（スキップオプション対応）\"\"\"\n",
    "    print(\"\\n🔍 ステップ1: 品質管理・デマルチプレックス開始\")\n",
    "    \n",
    "    # スキップオプションの確認\n",
    "    skip_demux = PROCESSING_OPTIONS.get('skip_demultiplex', False)\n",
    "    perform_qc = PROCESSING_OPTIONS.get('perform_quality_control', True)\n",
    "    \n",
    "    if skip_demux:\n",
    "        print(\"🚀 デマルチプレックスをスキップ（最近のシーケンサーでは既に実行済み）\")\n",
    "    if not perform_qc:\n",
    "        print(\"🚀 品質管理をスキップ\")\n",
    "    \n",
    "    for sample_name, fastq_paths in tqdm(INPUT_FASTQ_FILES.items(), desc=\"Processing samples\"):\n",
    "        # ペアエンドファイルの存在確認\n",
    "        r1_path = fastq_paths['R1']\n",
    "        r2_path = fastq_paths['R2']\n",
    "        \n",
    "        if not Path(r1_path).exists():\n",
    "            logger.warning(f\"⚠️ R1ファイルが見つかりません: {r1_path}\")\n",
    "            continue\n",
    "        if not Path(r2_path).exists():\n",
    "            logger.warning(f\"⚠️ R2ファイルが見つかりません: {r2_path}\")\n",
    "            continue\n",
    "        \n",
    "        # FastQC実行（オプション）\n",
    "        if perform_qc:\n",
    "            fastqc_cmd_r1 = f\"fastqc -o {PROJECT_ROOT}/data/processed/fastqc {r1_path}\"\n",
    "            fastqc_cmd_r2 = f\"fastqc -o {PROJECT_ROOT}/data/processed/fastqc {r2_path}\"\n",
    "            \n",
    "            run_command(fastqc_cmd_r1, f\"FastQC for {sample_name} R1\")\n",
    "            run_command(fastqc_cmd_r2, f\"FastQC for {sample_name} R2\")\n",
    "        else:\n",
    "            print(f\"⏭️ {sample_name}: FastQCをスキップしました\")\n",
    "        \n",
    "        # デマルチプレックス（オプション）\n",
    "        if not skip_demux and sample_name in BARCODES:\n",
    "            barcode = BARCODES[sample_name]\n",
    "            output_r1 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_1.fastq\"\n",
    "            output_r2 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_2.fastq\"\n",
    "            \n",
    "            # ペアエンドバーコード抽出\n",
    "            demux_cmd_r1 = f\"\"\"grep -A 3 \"^@.*{barcode}\" {r1_path} | grep -v \"^--$\" > {output_r1}\"\"\"\n",
    "            demux_cmd_r2 = f\"\"\"grep -A 3 \"^@.*{barcode}\" {r2_path} | grep -v \"^--$\" > {output_r2}\"\"\"\n",
    "            \n",
    "            run_command(demux_cmd_r1, f\"Demultiplexing {sample_name} R1\", check=False)\n",
    "            run_command(demux_cmd_r2, f\"Demultiplexing {sample_name} R2\", check=False)\n",
    "            \n",
    "            logger.info(f\"✅ {sample_name}: ペアエンドデマルチプレックス完了\")\n",
    "        elif skip_demux:\n",
    "            # デマルチプレックスをスキップする場合、元ファイルへのシンボリックリンクを作成\n",
    "            output_r1 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_1.fastq\"\n",
    "            output_r2 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_2.fastq\"\n",
    "            \n",
    "            # シンボリックリンク作成（既に存在する場合は削除）\n",
    "            if output_r1.exists():\n",
    "                output_r1.unlink()\n",
    "            if output_r2.exists():\n",
    "                output_r2.unlink()\n",
    "                \n",
    "            output_r1.symlink_to(Path(r1_path).absolute())\n",
    "            output_r2.symlink_to(Path(r2_path).absolute())\n",
    "            \n",
    "            logger.info(f\"✅ {sample_name}: デマルチプレックスをスキップ（シンボリックリンク作成）\")\n",
    "        else:\n",
    "            logger.warning(f\"⚠️ {sample_name}: バーコードが指定されていません\")\n",
    "    \n",
    "    skip_msg = []\n",
    "    if skip_demux:\n",
    "        skip_msg.append(\"デマルチプレックス\")\n",
    "    if not perform_qc:\n",
    "        skip_msg.append(\"品質管理\")\n",
    "    \n",
    "    completion_msg = \"✅ ステップ1完了: 品質管理・デマルチプレックス\"\n",
    "    if skip_msg:\n",
    "        completion_msg += f\"（{', '.join(skip_msg)}をスキップ）\"\n",
    "    \n",
    "    print(completion_msg)\n",
    "\n",
    "step1_quality_control_and_demultiplex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ステップ2: PCR重複除去・トリミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_remove_duplicates_and_trim():\n",
    "    \"\"\"ステップ2: PCR重複除去とトリミング（動的ファイル解決対応）\"\"\"\n",
    "    print(\"\\n✂️ ステップ2: PCR重複除去・トリミング開始（動的ファイル解決対応）\")\n",
    "    \n",
    "    # スキップオプションの確認\n",
    "    skip_trimming = PROCESSING_OPTIONS.get('skip_adapter_trimming', False)\n",
    "    skip_pcr_removal = PROCESSING_OPTIONS.get('skip_pcr_duplicate_removal', False)\n",
    "    \n",
    "    if skip_trimming:\n",
    "        print(\"🚀 アダプタートリミングをスキップ（最近のシーケンサーでは既に実行済み）\")\n",
    "    if skip_pcr_removal:\n",
    "        print(\"🚀 PCR重複除去をスキップ\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing trimming\"):\n",
    "        # 前ステップのファイルを動的に検索（デマルチプレックス済み）\n",
    "        input_r1 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_1.fastq\"\n",
    "        input_r2 = PROJECT_ROOT / f\"data/processed/{sample_name}_demux_2.fastq\"\n",
    "        \n",
    "        if not input_r1.exists() or not input_r2.exists():\n",
    "            logger.warning(f\"⚠️ {sample_name}: デマルチプレックス済みファイルが見つかりません\")\n",
    "            # 元ファイルの確認\n",
    "            original_r1 = Path(INPUT_FASTQ_FILES[sample_name]['R1'])\n",
    "            original_r2 = Path(INPUT_FASTQ_FILES[sample_name]['R2'])\n",
    "            if original_r1.exists() and original_r2.exists():\n",
    "                input_r1, input_r2 = original_r1, original_r2\n",
    "                logger.info(f\"📄 {sample_name}: 元ファイルを使用\")\n",
    "            else:\n",
    "                logger.error(f\"❌ {sample_name}: 入力ファイルが見つかりません\")\n",
    "                continue\n",
    "        \n",
    "        # PCR重複除去（オプション）\n",
    "        if not skip_pcr_removal:\n",
    "            rmdup_r1 = PROJECT_ROOT / f\"data/processed/{sample_name}_rmdup_1.fastq\"\n",
    "            rmdup_r2 = PROJECT_ROOT / f\"data/processed/{sample_name}_rmdup_2.fastq\"\n",
    "            \n",
    "            # ペアエンドPCR重複除去（簡易版）\n",
    "            rmdup_cmd_r1 = f\"\"\"awk '/^@/ {{if (seen[$0]++) next}} 1' {input_r1} > {rmdup_r1}\"\"\"\n",
    "            rmdup_cmd_r2 = f\"\"\"awk '/^@/ {{if (seen[$0]++) next}} 1' {input_r2} > {rmdup_r2}\"\"\"\n",
    "            \n",
    "            run_command(rmdup_cmd_r1, f\"Remove duplicates for {sample_name} R1\")\n",
    "            run_command(rmdup_cmd_r2, f\"Remove duplicates for {sample_name} R2\")\n",
    "            \n",
    "            # 次のステップの入力ファイルを更新\n",
    "            trim_input_r1 = rmdup_r1\n",
    "            trim_input_r2 = rmdup_r2\n",
    "        else:\n",
    "            print(f\"⏭️ {sample_name}: PCR重複除去をスキップしました\")\n",
    "            trim_input_r1 = input_r1\n",
    "            trim_input_r2 = input_r2\n",
    "        \n",
    "        # アダプタートリミング（オプション）\n",
    "        trimmed_r1 = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed_1.fastq\"\n",
    "        trimmed_r2 = PROJECT_ROOT / f\"data/processed/trimmed/{sample_name}_trimmed_2.fastq\"\n",
    "        \n",
    "        if not skip_trimming:\n",
    "            # ペアエンドアダプター除去とクオリティトリミング\n",
    "            adapter_r1 = PROCESSING_OPTIONS['adapter_sequences']['R1']\n",
    "            adapter_r2 = PROCESSING_OPTIONS['adapter_sequences']['R2']\n",
    "            \n",
    "            trim_cmd = f\"\"\"cutadapt -a {adapter_r1} -A {adapter_r2} \\\n",
    "                          -q 30 -m {ANALYSIS_PARAMS['min_read_length']} \\\n",
    "                          -o {trimmed_r1} -p {trimmed_r2} \\\n",
    "                          {trim_input_r1} {trim_input_r2}\"\"\"\n",
    "            \n",
    "            run_command(trim_cmd, f\"Paired-end adapter trimming for {sample_name}\", check=False)\n",
    "        else:\n",
    "            # トリミングをスキップする場合、シンボリックリンクを作成\n",
    "            if trimmed_r1.exists():\n",
    "                trimmed_r1.unlink()\n",
    "            if trimmed_r2.exists():\n",
    "                trimmed_r2.unlink()\n",
    "                \n",
    "            trimmed_r1.symlink_to(trim_input_r1.absolute())\n",
    "            trimmed_r2.symlink_to(trim_input_r2.absolute())\n",
    "            \n",
    "            print(f\"⏭️ {sample_name}: アダプタートリミングをスキップ（シンボリックリンク作成）\")\n",
    "        \n",
    "        logger.info(f\"✅ {sample_name}: 処理完了\")\n",
    "    \n",
    "    # 完了メッセージ作成\n",
    "    skip_msg = []\n",
    "    if skip_trimming:\n",
    "        skip_msg.append(\"アダプタートリミング\")\n",
    "    if skip_pcr_removal:\n",
    "        skip_msg.append(\"PCR重複除去\")\n",
    "    \n",
    "    completion_msg = \"✅ ステップ2完了: PCR重複除去・トリミング（動的ファイル解決対応）\"\n",
    "    if skip_msg:\n",
    "        completion_msg += f\"（{', '.join(skip_msg)}をスキップ）\"\n",
    "    \n",
    "    print(completion_msg)\n",
    "\n",
    "step2_remove_duplicates_and_trim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ステップ3: 配列アライメント・転写産物発現量計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_alignment_and_expression():\n",
    "    \"\"\"ステップ3: 配列アライメントと転写産物発現量計算（動的ファイル解決対応）\"\"\"\n",
    "    print(\"\\n🧬 ステップ3: アライメント・発現量計算開始（動的ファイル解決対応）\")\n",
    "    \n",
    "    for sample_name in tqdm(INPUT_FASTQ_FILES.keys(), desc=\"Processing alignment\"):\n",
    "        # 動的に最新の処理済みFASTQファイルを検索\n",
    "        fastq_files = find_latest_processed_files(sample_name, \"fastq\")\n",
    "        \n",
    "        if not fastq_files:\n",
    "            logger.error(f\"❌ {sample_name}: 処理済みFASTQファイルが見つかりません\")\n",
    "            continue\n",
    "            \n",
    "        trimmed_r1 = fastq_files[\"R1\"]\n",
    "        trimmed_r2 = fastq_files[\"R2\"]\n",
    "        \n",
    "        if not trimmed_r1.exists():\n",
    "            logger.warning(f\"⚠️ R1ファイルが見つかりません: {trimmed_r1}\")\n",
    "            continue\n",
    "        if not trimmed_r2.exists():\n",
    "            logger.warning(f\"⚠️ R2ファイルが見つかりません: {trimmed_r2}\")\n",
    "            continue\n",
    "        \n",
    "        # Bowtie2でペアエンドアライメント\n",
    "        sam_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.sam\"\n",
    "        \n",
    "        # ペアエンドマッピング（-1, -2でペアエンドファイル指定）\n",
    "        align_cmd = f\"\"\"bowtie2 -1 {trimmed_r1} -2 {trimmed_r2} -S {sam_file} \\\n",
    "                       -x {REFERENCE_FILES['transcriptome_index']} \\\n",
    "                       --non-deterministic --time \\\n",
    "                       --minins 50 --maxins 500 \\\n",
    "                       --no-mixed --no-discordant\"\"\"\n",
    "        \n",
    "        run_command(align_cmd, f\"Paired-end alignment for {sample_name}\")\n",
    "        \n",
    "        # RPKM計算\n",
    "        rpkm_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rpkm\"\n",
    "        rpkm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rpkm.py -i {sam_file} -o {rpkm_file}\"\"\"\n",
    "        \n",
    "        run_command(rpkm_cmd, f\"RPKM calculation for {sample_name}\", check=False)\n",
    "        \n",
    "        # RTstop計算\n",
    "        rt_file = PROJECT_ROOT / f\"data/processed/aligned/{sample_name}.rt\"\n",
    "        rt_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rtstops.py \\\n",
    "                    -i {sam_file} -o {rt_file} -r {rpkm_file} -c {ANALYSIS_PARAMS['min_rpkm']}\"\"\"\n",
    "        \n",
    "        run_command(rt_cmd, f\"RTstop calculation for {sample_name}\", check=False)\n",
    "        logger.info(f\"✅ {sample_name}: ペアエンドアライメント・発現量計算完了\")\n",
    "    \n",
    "    print(\"✅ ステップ3完了: アライメント・発現量計算（動的ファイル解決対応）\")\n",
    "\n",
    "step3_alignment_and_expression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ステップ4: RBRPスコア計算・統計解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def step4_rbrp_score_calculation():\n    \"\"\"ステップ4: RBRPスコア計算と統計解析（動的ファイル解決対応）\"\"\"\n    print(\"\\n📊 ステップ4: RBRPスコア計算・統計解析開始（動的ファイル解決対応）\")\n    \n    # SRA accession numbersに基づくサンプルグループ分け\n    # GSE229331のKool論文データ構成に基づく\n    probe_samples = [\n        'SRR22397001',  # HEK293_Probe2_only_rep1\n        'SRR22397002',  # HEK293_Probe2_only_rep2\n        'SRR22397003',  # HEK293_Probe2_Levofloxacin_rep1\n        'SRR22397004'   # HEK293_Probe2_Levofloxacin_rep2\n    ]\n    \n    control_samples = [\n        'SRR22397005',  # HEK293_DMSO_ctrl_rep1\n        'SRR22397006',  # HEK293_DMSO_ctrl_rep2\n        'SRR22397007',  # HEK293_Levofloxacin_ctrl_rep1\n        'SRR22397008'   # HEK293_Levofloxacin_ctrl_rep2\n    ]\n    \n    print(f\"📋 プローブサンプル: {probe_samples}\")\n    print(f\"📋 コントロールサンプル: {control_samples}\")\n    \n    # バックグラウンドRTstopファイルをマージ\n    if len(control_samples) >= 2:\n        control_files = []\n        for sample in control_samples:\n            rt_file = find_latest_processed_files(sample, \"rt\")\n            if rt_file and rt_file.exists():\n                control_files.append(str(rt_file))\n            else:\n                logger.warning(f\"⚠️ {sample}: RTファイルが見つかりません\")\n        \n        if control_files:\n            merged_control = PROJECT_ROOT / \"data/processed/rbrp_scores/merged_control.rt\"\n            merge_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/merge_rt_files.py \\\n                           -i {':'.join(control_files)} -o {merged_control}\"\"\"\n            run_command(merge_cmd, \"Merging control RTstop files\", check=False)\n    \n    # 各プローブサンプルのRBRPスコア計算\n    for sample_name in tqdm(probe_samples, desc=\"Calculating RBRP scores\"):\n        rt_file = find_latest_processed_files(sample_name, \"rt\")\n        \n        if not rt_file or not rt_file.exists():\n            logger.warning(f\"⚠️ {sample_name}: RTファイルが見つかりません\")\n            continue\n        \n        # RTファイル正規化\n        normalized_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_normalized.rt\"\n        norm_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/normalize_rt_file.py \\\n                      -i {rt_file} -o {normalized_file} -d 32 -l 32\"\"\"\n        run_command(norm_cmd, f\"Normalizing RT file for {sample_name}\", check=False)\n        \n        # RBRPスコア計算\n        rbrp_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_rbrp.out\"\n        background_file = merged_control if 'merged_control' in locals() else None\n        \n        if background_file and background_file.exists():\n            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n                          -f {normalized_file} -b {background_file} -o {rbrp_file} \\\n                          -e dividing -y 0.5\"\"\"\n        else:\n            rbrp_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/calculate_rbrp_score.py \\\n                          -f {normalized_file} -o {rbrp_file}\"\"\"\n        \n        run_command(rbrp_cmd, f\"Calculating RBRP scores for {sample_name}\", check=False)\n        \n        # 低品質スコアフィルタリング\n        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n        filter_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/filter_rbrp_scores.py \\\n                        -i {rbrp_file} -o {filtered_file} \\\n                        -t {ANALYSIS_PARAMS['min_sequencing_depth']} -s 5 -e 30\"\"\"\n        run_command(filter_cmd, f\"Filtering RBRP scores for {sample_name}\", check=False)\n        \n        logger.info(f\"✅ {sample_name}: RBRPスコア計算完了\")\n    \n    print(\"✅ ステップ4完了: RBRPスコア計算・統計解析（動的ファイル解決対応）\")\n\nstep4_rbrp_score_calculation()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ステップ5: 可視化ファイル生成・結果出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def step5_visualization_and_output():\n    \"\"\"ステップ5: 可視化ファイル生成と結果出力\"\"\"\n    print(\"\\n📈 ステップ5: 可視化ファイル生成・結果出力開始\")\n    \n    # プローブサンプルを定義（SRA accession numbers基準）\n    probe_samples = [\n        'SRR22397001',  # HEK293_Probe2_only_rep1\n        'SRR22397002',  # HEK293_Probe2_only_rep2\n        'SRR22397003',  # HEK293_Probe2_Levofloxacin_rep1\n        'SRR22397004'   # HEK293_Probe2_Levofloxacin_rep2\n    ]\n    \n    for sample_name in tqdm(probe_samples, desc=\"Generating visualization files\"):\n        filtered_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n        \n        if not filtered_file.exists():\n            logger.warning(f\"⚠️ フィルタリング済みファイルが見つかりません: {filtered_file}\")\n            continue\n        \n        # bedgraphファイル生成\n        bedgraph_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bedgraph\"\n        bedgraph_cmd = f\"\"\"python {PROJECT_ROOT}/scripts/generate_bedgraph.py \\\n                          -i {filtered_file} -o {bedgraph_file} \\\n                          -g {REFERENCE_FILES['genome_gtf']} \\\n                          -a {REFERENCE_FILES.get('transcriptome_fasta', '')}\"\"\"\n        run_command(bedgraph_cmd, f\"Generating bedgraph for {sample_name}\", check=False)\n        \n        # bigwigファイル生成（UCscツールが利用可能な場合）\n        bigwig_file = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}.bw\"\n        genome_size_file = PROJECT_ROOT / \"data/genome.size\"  # 事前に準備が必要\n        \n        if bedgraph_file.exists():\n            # ソートと重複除去\n            sorted_bedgraph = PROJECT_ROOT / f\"data/results/bigwig/{sample_name}_sorted.bedgraph\"\n            sort_cmd = f\"sort -k1,1 -k2,3n {bedgraph_file} | uniq > {sorted_bedgraph}\"\n            run_command(sort_cmd, f\"Sorting bedgraph for {sample_name}\", check=False)\n            \n            # bigwig変換\n            if genome_size_file.exists():\n                bw_cmd = f\"bedGraphToBigWig {sorted_bedgraph} {genome_size_file} {bigwig_file}\"\n                run_command(bw_cmd, f\"Converting to bigwig for {sample_name}\", check=False)\n        \n        logger.info(f\"✅ {sample_name}: 可視化ファイル生成完了\")\n    \n    print(\"✅ ステップ5完了: 可視化ファイル生成・結果出力\")\n\nstep5_visualization_and_output()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 結果サマリー・統計情報"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report():\n",
    "    \"\"\"結果サマリーレポート生成（動的ファイル解決対応）\"\"\"\n",
    "    print(\"\\n📋 結果サマリーレポート生成（動的ファイル解決対応）\")\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for sample_name in INPUT_FASTQ_FILES.keys():\n",
    "        sample_summary = {'sample_name': sample_name}\n",
    "        \n",
    "        # 動的ファイル検索結果を記録\n",
    "        fastq_files = find_latest_processed_files(sample_name, \"fastq\")\n",
    "        sam_file = find_latest_processed_files(sample_name, \"sam\")\n",
    "        rt_file = find_latest_processed_files(sample_name, \"rt\")\n",
    "        \n",
    "        # ファイル存在確認\n",
    "        sample_summary['input_files_exist'] = bool(fastq_files)\n",
    "        sample_summary['aligned_exists'] = bool(sam_file and sam_file.exists())\n",
    "        sample_summary['rt_analysis_exists'] = bool(rt_file and rt_file.exists())\n",
    "        \n",
    "        # RBRP スコアファイル確認\n",
    "        rbrp_file = PROJECT_ROOT / f\"data/processed/rbrp_scores/{sample_name}_filtered.out\"\n",
    "        sample_summary['rbrp_scores_exists'] = rbrp_file.exists()\n",
    "        \n",
    "        # ファイルサイズ情報\n",
    "        if fastq_files:\n",
    "            r1_size = fastq_files[\"R1\"].stat().st_size / (1024**2) if fastq_files[\"R1\"].exists() else 0\n",
    "            r2_size = fastq_files[\"R2\"].stat().st_size / (1024**2) if fastq_files[\"R2\"].exists() else 0\n",
    "            sample_summary['input_size_mb'] = round(r1_size + r2_size, 2)\n",
    "            sample_summary['processing_method'] = str(fastq_files[\"R1\"]).split('/')[-1].split('_')[1]  # demux, rmdup, trimmed\n",
    "        else:\n",
    "            sample_summary['input_size_mb'] = 0\n",
    "            sample_summary['processing_method'] = 'none'\n",
    "            \n",
    "        if sam_file and sam_file.exists():\n",
    "            sample_summary['aligned_size_mb'] = round(sam_file.stat().st_size / (1024**2), 2)\n",
    "        else:\n",
    "            sample_summary['aligned_size_mb'] = 0\n",
    "            \n",
    "        if rbrp_file.exists():\n",
    "            sample_summary['rbrp_size_mb'] = round(rbrp_file.stat().st_size / (1024**2), 2)\n",
    "        else:\n",
    "            sample_summary['rbrp_size_mb'] = 0\n",
    "        \n",
    "        # パイプライン完成度\n",
    "        completed_steps = sum([\n",
    "            sample_summary['input_files_exist'],\n",
    "            sample_summary['aligned_exists'], \n",
    "            sample_summary['rt_analysis_exists'],\n",
    "            sample_summary['rbrp_scores_exists']\n",
    "        ])\n",
    "        sample_summary['pipeline_completion'] = f\"{completed_steps}/4\"\n",
    "        sample_summary['pipeline_success'] = completed_steps == 4\n",
    "        \n",
    "        summary_data.append(sample_summary)\n",
    "    \n",
    "    # サマリーDataFrame作成\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # 結果表示\n",
    "    print(\"\\n📊 処理結果サマリー（動的ファイル解決対応）:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # CSVファイルとして保存\n",
    "    summary_file = PROJECT_ROOT / \"data/results/processing_summary_dynamic.csv\"\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    # 統計情報\n",
    "    successful_samples = summary_df['pipeline_success'].sum()\n",
    "    total_samples = len(summary_df)\n",
    "    \n",
    "    # 処理方法別の統計\n",
    "    processing_methods = summary_df['processing_method'].value_counts()\n",
    "    \n",
    "    print(f\"\\n📈 処理統計（動的ファイル解決対応）:\")\n",
    "    print(f\"   総サンプル数: {total_samples}\")\n",
    "    print(f\"   パイプライン完全成功: {successful_samples}\")\n",
    "    print(f\"   成功率: {successful_samples/total_samples*100:.1f}%\")\n",
    "    print(f\"   平均ファイルサイズ: {summary_df['input_size_mb'].mean():.1f} MB\")\n",
    "    print(f\"   使用された処理方法:\")\n",
    "    for method, count in processing_methods.items():\n",
    "        print(f\"     - {method}: {count} サンプル\")\n",
    "    print(f\"   サマリーファイル: {summary_file}\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "summary_report = generate_summary_report()\n",
    "\n",
    "# 実行時間の記録\n",
    "print(f\"\\n🎉 動的ファイル解決対応パイプライン実行完了!\")\n",
    "print(f\"📁 結果ファイルは以下に保存されました:\")\n",
    "print(f\"   - 処理済みデータ: {PROJECT_ROOT}/data/processed/\")\n",
    "print(f\"   - 最終結果: {PROJECT_ROOT}/data/results/\")\n",
    "print(f\"   - ログファイル: {log_file}\")\n",
    "\n",
    "logger.info(\"RBRP Dry Protocol Pipeline (Dynamic File Resolution) completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 結果可視化（オプション）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization_plots():\n",
    "    \"\"\"結果の可視化プロット作成\"\"\"\n",
    "    print(\"\\n📊 結果可視化プロット作成\")\n",
    "    \n",
    "    # 処理サマリーの可視化\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('RBRP Dry Protocol - 処理結果サマリー', fontsize=16, y=0.98)\n",
    "    \n",
    "    # 1. ファイルサイズ分布\n",
    "    size_columns = [col for col in summary_report.columns if 'size_mb' in col]\n",
    "    if size_columns:\n",
    "        size_data = summary_report[size_columns].fillna(0)\n",
    "        axes[0, 0].bar(range(len(size_columns)), size_data.mean(), \n",
    "                      tick_label=[col.replace('_size_mb', '') for col in size_columns])\n",
    "        axes[0, 0].set_title('平均ファイルサイズ (MB)')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. 処理成功率\n",
    "    success_columns = [col for col in summary_report.columns if 'exists' in col]\n",
    "    if success_columns:\n",
    "        success_rates = summary_report[success_columns].mean() * 100\n",
    "        axes[0, 1].bar(range(len(success_rates)), success_rates.values,\n",
    "                      tick_label=[col.replace('_exists', '') for col in success_columns])\n",
    "        axes[0, 1].set_title('処理成功率 (%)')\n",
    "        axes[0, 1].set_ylim(0, 100)\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. サンプル別処理状況\n",
    "    if success_columns:\n",
    "        sample_success = summary_report[success_columns].sum(axis=1)\n",
    "        axes[1, 0].bar(range(len(sample_success)), sample_success.values,\n",
    "                      tick_label=summary_report['sample_name'])\n",
    "        axes[1, 0].set_title('サンプル別完了ステップ数')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. 処理時間の目安（仮想データ）\n",
    "    processing_steps = ['デマルチプレックス', 'トリミング', 'アライメント', 'RBRP計算', '可視化']\n",
    "    estimated_times = [5, 10, 30, 20, 5]  # 分単位\n",
    "    axes[1, 1].bar(processing_steps, estimated_times)\n",
    "    axes[1, 1].set_title('ステップ別推定処理時間 (分)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 図を保存\n",
    "    plot_file = PROJECT_ROOT / \"data/results/figures/processing_summary.png\"\n",
    "    plt.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"📊 可視化プロット保存: {plot_file}\")\n",
    "\n",
    "# 可視化実行\n",
    "try:\n",
    "    create_visualization_plots()\n",
    "except Exception as e:\n",
    "    logger.warning(f\"可視化プロット作成エラー: {e}\")\n",
    "    print(\"⚠️ 可視化プロットの作成でエラーが発生しましたが、パイプライン自体は正常に完了しています\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sidework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}